# dand
Udacity Data Analyst Nanodegree

## Project 1 - Explore weather trends

This project explores the fluctuations of the average weather temperature in the world and two other cities : Sidney and Brussels where I'm currently living. From the comparison I identified few trends and proposed some possible explorations to go further in the explaination of the trends.

Go to [Project 1 - Explore weather trends](P1-explore_weather_trends)

## Project 2 - Investigate a Dataset

This analysis on movie data aims to figure out over the past six decades :

* what are the most popular genres over the years
* what are the characteristic of the most profitable movies
* do most popular genres make more profit  

This investigation is based on a cleansed dataset which originally comes from [Kaggle - TMDb movie metadata](https://www.kaggle.com/tmdb/tmdb-movie-metadata)

After completing the project, I learn how to:

* Know all the steps involved in a typical data analysis process
* Be comfortable posing questions that can be answered with a given dataset and then answering those questions
* Know how to investigate problems in a dataset and wrangle the data into a format you can use
* Have experience communicating the results of your analysis
* Be able to use vectorized operations in NumPy and pandas to speed up your data analysis code
*Be familiar with pandas' Series and DataFrame objects, which let you access your data more conveniently
* Know how to use Matplotlib to produce plots showing your findings

Go to [Project 2 - Investigate a Dataset](P2-investigate_a_dataset)

## Project 3 - Analyze A/B Test Results

A/B tests are very commonly performed by data analysts and data scientists. 

This project aim at understand the results of an A/B test run by an e-commerce website. The company has developed a new web page in order to try and increase the number of users who "convert," meaning the number of users who decide to pay for the company's product. The final purpose is to decide rather or not to release the new design because it should lead to a higher conversion rate.

After completing the project, I learn:
* how I can use several "tools" to analyze observations: Probability, statitics and supervised traineing
* how they differ one from another and when one is more relevant.

Go to [Project 3 - Analyze A/B testing](P3-AB_Analysis)

## Project 4 - Wrangle and Analyze Data

Real-world data rarely comes clean. Using Python and its libraries, you will gather data from a variety of sources and in a variety of formats, assess its quality and tidiness, then clean it. This is called data wrangling. 

[We rate dog](https://en.wikipedia.org/wiki/WeRateDogs) is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because "[they're good dogs Brent](https://knowyourmeme.com/memes/theyre-good-dogs-brent)." WeRateDogs has over 4 million followers and has received international media coverage.

I start with the dataset that WeRateDog provided to Udacity as an archive. This archive contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017. More on this soon. 

After completing the project, I learn how to:

* use python libraries and principles such as [data tidiness](https://ryanwingate.com/purpose/tidy-data/) to achieve the three steps of Data Wrangling
  - Gather
  - Assess
  - Clean
* analyze the clean data

Go to [Project 4 - Wrangle and Analyze Data](P4-Data_wrangle)

## Project 5 - Data visualization

This project has two parts that demonstrate the importance and value of data visualization techniques in the data analysis process. First part make use of Python visualization libraries to systematically explore a selected dataset, starting from plots of single variables and building up to plots of multiple variables. Second part aim at producing a short presentation that illustrates interesting properties, trends, and relationships that you discovered in your selected dataset. The primary method of conveying the findings will be through transforming the exploratory visualizations from the first part into polished, explanatory visualizations.

I choose to work on the PISA 2012 survey. The Programme for International Student Assessment (PISA) is a triennial international survey which aims to evaluate education systems worldwide by testing the skills and knowledge of 15-year-old students who are nearing the end of their compulsory education. PISA assesses how well they can apply what they learn in school to real-life situations.

This dataset contains the result of the survey for 2012.

After completing the project, I learn how to:

* use univariate, bivariate, and multivariate plots to explore relationship in the dataset.
* depict my findings with the appropriate plots
* tell a friendly story by making a slide deck from a notebook. The making of implies organising the findings of the exploration into a story then choosing and polishing the plots that would best illustrate the findings.

Go to [Project 5 - Data visualization](P5-Data_visualization)


![dand_certificate](dand_certificat.svg)